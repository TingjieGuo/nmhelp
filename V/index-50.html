<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
<HEAD>
<TITLE>Page 50</TITLE>

<META http-equiv="Content-Type" content="text/html; charset=UTF-8">
<DIV style="position:relative;width:612;height:792;">
<STYLE type="text/css">
<!--
	.ft0{font-size:9px;font-family:Times;color:#000000;}
	.ft1{font-size:9px;font-family:Times;color:#000000;}
	.ft2{font-size:8px;font-family:Symbol;color:#000000;}
	.ft3{font-size:9px;font-family:Symbol;color:#000000;}
	.ft4{font-size:5px;font-family:Times;color:#000000;}
	.ft5{font-size:3px;font-family:Times;color:#000000;}
	.ft6{font-size:9px;font-family:Times;color:#000000;}
	.ft7{font-size:13px;font-family:Symbol;color:#000000;}
	.ft8{font-size:11px;font-family:Helvetica;color:#000000;}
	.ft9{font-size:14px;font-family:Helvetica;color:#000000;}
	.ft10{font-size:7px;font-family:Times;color:#000000;}
	.ft11{font-size:5px;font-family:Times;color:#000000;}
	.ft12{font-size:9px;line-height:13px;font-family:Times;color:#000000;}
	.ft13{font-size:3px;line-height:5px;font-family:Times;color:#000000;}
-->
</STYLE>
</HEAD>
<BODY bgcolor="#A0A0A0" vlink="blue" link="blue">
<IMG width="612" height="792" src="index050.png" alt="background image">
<DIV style="position:absolute;top:41;left:214"><nobr><span class="ft0">Chapter 5 - Estimates, Conﬁdence Intervals, and Hypothesis Tests</span></nobr></DIV>
<DIV style="position:absolute;top:77;left:72"><nobr><span class="ft12">It is always possible, of course, to parameterize the model in the function of interest. For exam-<br>ple, we have already seen (Chapters 2 &amp; 3) that we may use the function (parameter) <i>Cl </i>in the<br>one-compartment model instead of <i>k</i>. Howev er, we may be interested in the values of several<br>alternative parameterizations (e.g., we may want to know k, clearance, and half-life). Rather than<br>rerun the same problem with several alternative parameterizations, we can use the fact that the LS<br>estimate of a function of the parameters is given by the same function of the LS parameter esti-<br>mates. Formally, if</span></nobr></DIV>
<DIV style="position:absolute;top:153;left:162"><nobr><span class="ft2">θ</span></nobr></DIV>
<DIV style="position:absolute;top:152;left:168"><nobr><span class="ft3">′ =</span></nobr></DIV>
<DIV style="position:absolute;top:155;left:184"><nobr><span class="ft1"><i>q</i>(</span></nobr></DIV>
<DIV style="position:absolute;top:153;left:192"><nobr><span class="ft2">θ</span></nobr></DIV>
<DIV style="position:absolute;top:155;left:199"><nobr><span class="ft0">) is the function of interest, then ˆ</span></nobr></DIV>
<DIV style="position:absolute;top:153;left:347"><nobr><span class="ft2">θ</span></nobr></DIV>
<DIV style="position:absolute;top:152;left:353"><nobr><span class="ft3">′</span></nobr></DIV>
<DIV style="position:absolute;top:160;left:356"><nobr><span class="ft4"><i>LS</i></span></nobr></DIV>
<DIV style="position:absolute;top:152;left:369"><nobr><span class="ft3">=</span></nobr></DIV>
<DIV style="position:absolute;top:155;left:378"><nobr><span class="ft1"><i>q</i>( ˆ</span></nobr></DIV>
<DIV style="position:absolute;top:153;left:387"><nobr><span class="ft2">θ</span></nobr></DIV>
<DIV style="position:absolute;top:160;left:394"><nobr><span class="ft4"><i>LS</i></span></nobr></DIV>
<DIV style="position:absolute;top:155;left:403"><nobr><span class="ft0">). E.g. Letting</span></nobr></DIV>
<DIV style="position:absolute;top:153;left:471"><nobr><span class="ft2">θ</span></nobr></DIV>
<DIV style="position:absolute;top:152;left:478"><nobr><span class="ft3">′ =</span></nobr></DIV>
<DIV style="position:absolute;top:155;left:493"><nobr><span class="ft1"><i>t</i></span></nobr></DIV>
<DIV style="position:absolute;top:159;left:497"><nobr><span class="ft13">1<br>2</span></nobr></DIV>
<DIV style="position:absolute;top:155;left:501"><nobr><span class="ft0">,</span></nobr></DIV>
<DIV style="position:absolute;top:168;left:71"><nobr><span class="ft2">θ</span></nobr></DIV>
<DIV style="position:absolute;top:167;left:81"><nobr><span class="ft3">=</span></nobr></DIV>
<DIV style="position:absolute;top:171;left:91"><nobr><span class="ft1"><i>k</i>, and <i>q</i>(</span></nobr></DIV>
<DIV style="position:absolute;top:168;left:130"><nobr><span class="ft2">θ</span></nobr></DIV>
<DIV style="position:absolute;top:171;left:136"><nobr><span class="ft0">)</span></nobr></DIV>
<DIV style="position:absolute;top:167;left:143"><nobr><span class="ft3">=</span></nobr></DIV>
<DIV style="position:absolute;top:171;left:152"><nobr><span class="ft0">. 693 /</span></nobr></DIV>
<DIV style="position:absolute;top:168;left:176"><nobr><span class="ft2">θ</span></nobr></DIV>
<DIV style="position:absolute;top:171;left:183"><nobr><span class="ft0">, then ˆ<i>t</i></span></nobr></DIV>
<DIV style="position:absolute;top:174;left:215"><nobr><span class="ft13">1<br>2</span></nobr></DIV>
<DIV style="position:absolute;top:167;left:222"><nobr><span class="ft3">=</span></nobr></DIV>
<DIV style="position:absolute;top:171;left:231"><nobr><span class="ft0">. 693 / ˆ</span></nobr></DIV>
<DIV style="position:absolute;top:171;left:256"><nobr><span class="ft1"><i>k</i>.</span></nobr></DIV>
<DIV style="position:absolute;top:198;left:72"><nobr><span class="ft6"><b>4. Precision of Parameter Estimates</b></span></nobr></DIV>
<DIV style="position:absolute;top:215;left:72"><nobr><span class="ft12">Clearly, it is almost impossible for the estimates to actually be the true values. The question is:<br>how far are the true values from the estimates? To discuss this question, imagine replicating the<br>entire experiment (gathering new data, but keeping <i>x </i>ﬁxed) multiple times. Also, for simplicity,<br>imagine that the model has only one scalar parameter,</span></nobr></DIV>
<DIV style="position:absolute;top:251;left:315"><nobr><span class="ft2">θ</span></nobr></DIV>
<DIV style="position:absolute;top:254;left:322"><nobr><span class="ft0">, and that its true value,</span></nobr></DIV>
<DIV style="position:absolute;top:251;left:430"><nobr><span class="ft2">θ</span></nobr></DIV>
<DIV style="position:absolute;top:259;left:436"><nobr><span class="ft4"><i>T</i></span></nobr></DIV>
<DIV style="position:absolute;top:254;left:445"><nobr><span class="ft0">is known. If,</span></nobr></DIV>
<DIV style="position:absolute;top:267;left:72"><nobr><span class="ft0">after each replication, the estimate of</span></nobr></DIV>
<DIV style="position:absolute;top:264;left:237"><nobr><span class="ft2">θ</span></nobr></DIV>
<DIV style="position:absolute;top:267;left:247"><nobr><span class="ft0">is recorded, and a histogram of these values is plotted, one</span></nobr></DIV>
<DIV style="position:absolute;top:280;left:72"><nobr><span class="ft0">might see something like ﬁgure 5.1A or 5.1B.</span></nobr></DIV>
<DIV style="position:absolute;top:448;left:404"><nobr><span class="ft7">θ</span></nobr></DIV>
<DIV style="position:absolute;top:461;left:412"><nobr><span class="ft8">T</span></nobr></DIV>
<DIV style="position:absolute;top:448;left:166"><nobr><span class="ft7">θ</span></nobr></DIV>
<DIV style="position:absolute;top:461;left:175"><nobr><span class="ft8">T</span></nobr></DIV>
<DIV style="position:absolute;top:309;left:72"><nobr><span class="ft9">A.</span></nobr></DIV>
<DIV style="position:absolute;top:309;left:309"><nobr><span class="ft9">B.</span></nobr></DIV>
<DIV style="position:absolute;top:491;left:72"><nobr><span class="ft10">Figure 5.1. Tw o hypothetical histograms of estimates of a single parameter upon replication of a given experiment.</span></nobr></DIV>
<DIV style="position:absolute;top:504;left:72"><nobr><span class="ft10">Left panel (A): The estimates have small variance (spread) but are biased (the mean of the estimates differs from the</span></nobr></DIV>
<DIV style="position:absolute;top:517;left:72"><nobr><span class="ft10">true value,</span></nobr></DIV>
<DIV style="position:absolute;top:512;left:111"><nobr><span class="ft2">θ</span></nobr></DIV>
<DIV style="position:absolute;top:520;left:118"><nobr><span class="ft4"><i>T</i></span></nobr></DIV>
<DIV style="position:absolute;top:517;left:123"><nobr><span class="ft10">); Right panel: The estimates have large variance but are relatively unbiased.</span></nobr></DIV>
<DIV style="position:absolute;top:545;left:72"><nobr><span class="ft0">The difference between the estimate and the true value,</span></nobr></DIV>
<DIV style="position:absolute;top:542;left:323"><nobr><span class="ft2">θ</span></nobr></DIV>
<DIV style="position:absolute;top:549;left:330"><nobr><span class="ft4"><i>T</i></span></nobr></DIV>
<DIV style="position:absolute;top:545;left:335"><nobr><span class="ft0">, obviously differs from replication to</span></nobr></DIV>
<DIV style="position:absolute;top:558;left:72"><nobr><span class="ft12">replication. Let this difference be called the estimation error. We cannot know the estimation er-<br>ror of any particular estimate (if we could, we could know the true value itself, by subtraction),<br>but we can hope to estimate the mean error magnitude. Since errors can be positive or neg ative, a<br>measure of magnitude that is unaffected by sign is desirable. This is traditionally the Mean<br>Squared Error (<i>MSE</i>). The MSE can be factored into two parts:</span></nobr></DIV>
<DIV style="position:absolute;top:629;left:250"><nobr><span class="ft1"><i>MSE</i></span></nobr></DIV>
<DIV style="position:absolute;top:626;left:275"><nobr><span class="ft3">=</span></nobr></DIV>
<DIV style="position:absolute;top:629;left:285"><nobr><span class="ft1"><i>B</i></span></nobr></DIV>
<DIV style="position:absolute;top:627;left:292"><nobr><span class="ft11">2</span></nobr></DIV>
<DIV style="position:absolute;top:626;left:300"><nobr><span class="ft3">+</span></nobr></DIV>
<DIV style="position:absolute;top:629;left:309"><nobr><span class="ft1"><i>SE</i></span></nobr></DIV>
<DIV style="position:absolute;top:627;left:322"><nobr><span class="ft11">2</span></nobr></DIV>
<DIV style="position:absolute;top:629;left:483"><nobr><span class="ft0">(5.2)</span></nobr></DIV>
<DIV style="position:absolute;top:648;left:72"><nobr><span class="ft12">where <i>B </i>is the bias of the estimates (mean (signed) difference between the estimates and the true<br>value) and <i>SE </i>is the standard error of the estimates (<i>SE</i></span></nobr></DIV>
<DIV style="position:absolute;top:659;left:329"><nobr><span class="ft11">2</span></nobr></DIV>
<DIV style="position:absolute;top:662;left:337"><nobr><span class="ft0">is the variance of the estimates). As</span></nobr></DIV>
<DIV style="position:absolute;top:675;left:72"><nobr><span class="ft12">illustrated in ﬁgure 5.1, the <i>MSE </i>can be about the same for two types of estimates while both<br>their bias and <i>SE </i>differ. It is very hard to estimate the bias of an estimator unless the true param-<br>eter value is, in fact, known. This is not true of the <i>SE</i>: the standard deviation of the distribution<br>of estimates of a parameter on replication is the <i>SE</i>; no knowledge of the true value of the</span></nobr></DIV>
<DIV style="position:absolute;top:761;left:279"><nobr><span class="ft0">-42-</span></nobr></DIV>
</DIV>
</BODY>
</HTML>
